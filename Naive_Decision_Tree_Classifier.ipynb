{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4511133,"sourceType":"datasetVersion","datasetId":2636290}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\n\n# 路徑設置\nfor dirname, _, filenames in os.walk('/kaggle/input/carinsuranceclaimprediction-classification'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# 讀取 CSV 文件\ncsv_path = '/kaggle/input/carinsuranceclaimprediction-classification/train.csv'\ntrainData = pd.read_csv(csv_path, header=0)\n# 刪除第一、十一、十二列的單元格\ntrainData = trainData.drop(columns=[trainData.columns[0], trainData.columns[10], trainData.columns[11]])","metadata":{"execution":{"iopub.status.busy":"2023-11-04T15:10:09.308371Z","iopub.execute_input":"2023-11-04T15:10:09.308931Z","iopub.status.idle":"2023-11-04T15:10:09.779146Z","shell.execute_reply.started":"2023-11-04T15:10:09.308876Z","shell.execute_reply":"2023-11-04T15:10:09.777970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定義一個自定義函數，對非數字進行編碼\ndef encode_non_numeric(column):\n    if column.dtype == 'object':\n        return column.astype('category').cat.codes\n    return column\n\n# 將所有非數字的單元格進行編碼\ntrainData = trainData.apply(encode_non_numeric)\n\n# 划分数据集\ndef split_dataset(data, test_size=0.2):\n    # 随机打乱数据集\n    data = data.sample(frac=1.0, random_state=42).reset_index(drop=True)\n    \n    # 计算测试集的大小\n    test_data_size = int(test_size * len(data))\n    \n    # 划分数据集\n    test_data = data[:test_data_size]\n    train_data = data[test_data_size:]\n    \n    return train_data, test_data","metadata":{"execution":{"iopub.status.busy":"2023-11-04T15:10:09.780987Z","iopub.execute_input":"2023-11-04T15:10:09.781311Z","iopub.status.idle":"2023-11-04T15:10:09.956760Z","shell.execute_reply.started":"2023-11-04T15:10:09.781284Z","shell.execute_reply":"2023-11-04T15:10:09.955725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义节点类\nclass Node:\n    def __init__(self, value=None, true_branch=None, false_branch=None, is_leaf=False):\n        self.value = value\n        self.true_branch = true_branch\n        self.false_branch = false_branch\n        self.is_leaf = is_leaf","metadata":{"execution":{"iopub.status.busy":"2023-11-04T15:10:09.957993Z","iopub.execute_input":"2023-11-04T15:10:09.958293Z","iopub.status.idle":"2023-11-04T15:10:09.964225Z","shell.execute_reply.started":"2023-11-04T15:10:09.958266Z","shell.execute_reply":"2023-11-04T15:10:09.963313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DecisionTree:\n    # 添加一个属性来保存每一次迭代的性能指标\n    def __init__(self, max_depth=None):\n        self.max_depth = max_depth\n        self.best_gini = float('inf')\n        self.best_criteria = None\n        self.best_sets = None\n        self.tree = None\n        self.history = {'depth': [], 'train_accuracy': [], 'train_loss': [], 'test_accuracy': [], 'test_loss': []}\n\n    def find_best_split(self, data):\n        features = data.columns[:-1]\n        self.best_gini = float('inf')  # 重置best_gini\n        for feature in features:\n            unique_values = data[feature].unique()\n\n            for value in unique_values:\n                true_data, false_data = self.split_data(data, feature, value)\n                gini = (len(true_data) / len(data)) * self.calculate_gini(true_data) + \\\n                       (len(false_data) / len(data)) * self.calculate_gini(false_data)\n\n                if gini < self.best_gini:\n                    self.best_gini = gini\n                    self.best_criteria = (feature, value)\n                    self.best_sets = (true_data, false_data)\n\n        return self.best_criteria, self.best_sets\n\n    def build_tree(self, data, depth=0):\n        if depth == self.max_depth or self.best_sets is None:\n            return Node(value=data['is_claim'].mode()[0], is_leaf=True)\n\n        best_criteria, best_sets = self.find_best_split(data)\n\n        if self.best_gini == 0:\n            return Node(value=best_sets[0]['is_claim'].mode()[0], is_leaf=True)\n\n        true_branch = self.build_tree(best_sets[0], depth + 1)\n        false_branch = self.build_tree(best_sets[1], depth + 1)\n\n        return Node(value=best_criteria, true_branch=true_branch, false_branch=false_branch)\n\n    def train(self, train_data, test_data=None):\n        # 重构训练函数，根据每个深度构建树并评估性能\n        for depth in range(1, self.max_depth + 1):\n            self.tree = self.build_tree(train_data, depth)\n            self.evaluate(train_data, test_data, depth)\n            \n            # 計算訓練集的準確度和損失\n            train_predictions = self.predict(train_data.drop(columns=['is_claim']))\n            train_labels = train_data['is_claim'].values\n            train_accuracy = np.sum(train_predictions == train_labels) / len(train_labels)\n            train_loss = self.calculate_gini(train_data[train_data['is_claim'] != train_predictions])\n            \n    def evaluate(self, train_data, test_data, depth):\n        # 计算训练集的准确度和损失\n        train_predictions = self.predict(train_data.drop(columns=['is_claim']))\n        train_labels = train_data['is_claim'].values\n        train_accuracy = np.sum(train_predictions == train_labels) / len(train_labels)\n        train_loss = self.calculate_gini(train_data)\n\n        # 保存训练集的性能\n        self.history['depth'].append(depth)\n        self.history['train_accuracy'].append(train_accuracy)\n        self.history['train_loss'].append(train_loss)\n\n        if test_data is not None:\n            # 计算测试集的准确度和损失\n            test_predictions = self.predict(test_data.drop(columns=['is_claim']))\n            test_labels = test_data['is_claim'].values\n            test_accuracy = np.sum(test_predictions == test_labels) / len(test_labels)\n            test_loss = self.calculate_gini(test_data)\n\n            # 保存测试集的性能\n            self.history['test_accuracy'].append(test_accuracy)\n            self.history['test_loss'].append(test_loss)\n                \n    # 添加一个方法来计算Gini不纯度作为损失\n    def calculate_gini(self, data):\n        if len(data) == 0:\n            return 0\n        else:\n            proportions = data['is_claim'].value_counts(normalize=True)\n            gini = 1 - sum(proportions ** 2)\n            return gini\n\n    # 预测单个样本\n    def predict_sample(self, node, sample):\n        if node.is_leaf:\n            return node.value\n\n        feature, value = node.value\n        if sample[feature] <= value:\n            return self.predict_sample(node.true_branch, sample)\n        else:\n            return self.predict_sample(node.false_branch, sample)\n\n    # 预测数据集\n    def predict(self, data):\n        predictions = np.array([self.predict_sample(self.tree, row) for _, row in data.iterrows()])\n        return predictions","metadata":{"execution":{"iopub.status.busy":"2023-11-04T15:10:09.966155Z","iopub.execute_input":"2023-11-04T15:10:09.967263Z","iopub.status.idle":"2023-11-04T15:10:09.994594Z","shell.execute_reply.started":"2023-11-04T15:10:09.967219Z","shell.execute_reply":"2023-11-04T15:10:09.993491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 划分数据集\ntrainData, testData = split_dataset(trainData)\n\nprint(\"Training set size:\", trainData.shape)\nprint(\"Validation set size:\", testData.shape)\n\n# 使用上述决策树类进行训练和预测\ntree = DecisionTree(max_depth=5) # 假设我们想要训练深度为1到5的树\ntree.train(trainData, testData)\n\n# 预测训练集数据\ntrain_predictions = tree.predict(trainData.drop(columns=['is_claim']))\ntrain_labels = trainData['is_claim'].values\n\n# 计算训练集准确度和损失\ntrain_accuracy = np.sum(train_predictions == train_labels) / len(train_labels)\n\n\n# 预测测试集数据\ntest_predictions = tree.predict(testData.drop(columns=['is_claim']))\ntest_labels = testData['is_claim'].values\n\n# 计算测试集准确度\ntest_accuracy = np.sum(test_predictions == test_labels) / len(test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T15:10:09.996238Z","iopub.execute_input":"2023-11-04T15:10:09.996644Z","iopub.status.idle":"2023-11-04T15:10:36.898405Z","shell.execute_reply.started":"2023-11-04T15:10:09.996608Z","shell.execute_reply":"2023-11-04T15:10:36.897288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 繪製性能圖表\nplt.figure(figsize=(10, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(tree.history['depth'], tree.history['train_accuracy'], label='Train Accuracy')\nplt.plot(tree.history['depth'], tree.history['test_accuracy'], label='Test Accuracy')\nplt.xlabel('Depth of tree')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(tree.history['depth'], tree.history['train_loss'], label='Train Loss')\nplt.plot(tree.history['depth'], tree.history['test_loss'], label='Test Loss')\nplt.xlabel('Depth of tree')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(tree.history['train_loss'])\nprint(tree.history['test_loss'])\nprint(f'Average Testing Accuracy: {test_accuracy:.4f}')\nprint(f'Average Training Accuracy: {train_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-11-04T15:11:40.420706Z","iopub.execute_input":"2023-11-04T15:11:40.421115Z","iopub.status.idle":"2023-11-04T15:11:41.206206Z","shell.execute_reply.started":"2023-11-04T15:11:40.421084Z","shell.execute_reply":"2023-11-04T15:11:41.205001Z"},"trusted":true},"execution_count":null,"outputs":[]}]}